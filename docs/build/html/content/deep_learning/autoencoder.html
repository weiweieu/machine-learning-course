

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Autoencoders &mdash; Machine-Learning-Course 1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="LICENSE" href="../../credentials/LICENSE.html" />
    <link rel="prev" title="Convolutional Neural Networks" href="cnn.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Foreword</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro/intro.html">Introduction</a></li>
</ul>
<p class="caption"><span class="caption-text">Core Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview/crossvalidation.html">Cross-Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/linear-regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/overfitting.html">Overfitting and Underfitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/regularization.html">Regularization</a></li>
</ul>
<p class="caption"><span class="caption-text">Supervised Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../supervised/logistic_regression.html">Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/bayes.html">Naive Bayes Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/decisiontrees.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/knn.html">k-Nearest Neighbors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/linear_SVM.html">Linear Support Vector Machines</a></li>
</ul>
<p class="caption"><span class="caption-text">Unsupervised Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised/clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised/pca.html">Principal Component Analysis</a></li>
</ul>
<p class="caption"><span class="caption-text">Deep Learning</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mlp.html">Multi-layer Perceptron</a></li>
<li class="toctree-l1"><a class="reference internal" href="cnn.html">Convolutional Neural Networks</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Autoencoders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#autoencoders-and-their-implementations-in-tensorflow">Autoencoders and their implementations in TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#create-an-undercomplete-autoencoder">Create an Undercomplete Autoencoder</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Document Credentials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../credentials/LICENSE.html">LICENSE</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Machine-Learning-Course</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>Autoencoders</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com///blob/content/deep_learning/autoencoder.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="autoencoders">
<h1>Autoencoders<a class="headerlink" href="#autoencoders" title="Permalink to this headline">¶</a></h1>
<div class="section" id="autoencoders-and-their-implementations-in-tensorflow">
<h2>Autoencoders and their implementations in TensorFlow<a class="headerlink" href="#autoencoders-and-their-implementations-in-tensorflow" title="Permalink to this headline">¶</a></h2>
<p>In this post, you will learn the notion behind Autoencoders as well as how
to implement an autoencoder in TensorFlow.</p>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Autoencoders are a kind of neural networks which imitate their inputs and produce the
exact information at their outputs. They usually include two parts: Encoder and Decoder.
The encoder transforms the input into a hidden space (hidden layer). The decoder then
reconstructs the input information as the output. There are various types of autoencoders:</p>
<ul class="simple">
<li><strong>Undercomplete Autoencoders:</strong> In this type, the hidden dimension is smaller than the input dimension.
Training such autoencoder lead to capturing the most prominent features. However, using an overparameterized
architecture in case of a lack of sufficient training data create overfitting and bars learning valuable features.
A linear decoder can operate as PCA. However, the existence of non-linear functions create a more powerful
dimensionality reduction model.</li>
<li><strong>Regularized Autoencoders:</strong> Instead of limiting the dimension of an autoencoder and the hidden
layer size for feature learning, a loss function will be added to prevent overfitting.</li>
<li><strong>Sparse Autoencoders:</strong> Sparse autoencoders allow for representing the information bottleneck
without demanding a decrease in the size of the hidden layer. Instead, it operates based on a loss
function that penalizes the activations inside a layer.</li>
<li><strong>Denoising Autoencoders (DAE):</strong> We want an autoencoder to be sufficiently sensitive to regenerate
the original input but not strictly sensitive so the model can learn a generalizable encoding and decoding.
The approach is to insignificantly corrupt the input data with some noise with an uncorrupted data as the target output..</li>
<li><strong>Contractive Autoencoders (CAE):</strong> In this type of autoencoders, for small input variations,
the encoded features should also be very similar. Denoising autoencoders force the reconstruction
function to resist minor changes of the input, while contractive autoencoders enforce the encoder
to resist against the input perturbation.</li>
<li><strong>Variational Autoencoders:</strong> A variational autoencoder (VAE) presents a probabilistic fashion
for explaining an observation in hidden space. Therefore, instead of creating an encoder
which results in a value to represent each latent feature, the encoder produces a probability
distribution for each hidden feature.</li>
</ul>
<p>In this post, we are going to design an Undercomplete Autoencoder
in TensorFlow to train a low dimension representation.</p>
</div>
<div class="section" id="create-an-undercomplete-autoencoder">
<h2>Create an Undercomplete Autoencoder<a class="headerlink" href="#create-an-undercomplete-autoencoder" title="Permalink to this headline">¶</a></h2>
<p>We are working on building an autoencoder with a 3-layer encoder and 3-layer decoder. Each layer of encoder compresses its input along the spatial
dimensions by a factor of two. Similarly, each segment of the
decoder increases its input dimensionality by a factor of two.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow.contrib.layers</span> <span class="kn">as</span> <span class="nn">lays</span>

<span class="k">def</span> <span class="nf">autoencoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
    <span class="c1"># encoder</span>
    <span class="c1"># 32 file code blockx 32 x 1   -&gt;  16 x 16 x 32</span>
    <span class="c1"># 16 x 16 x 32  -&gt;  8 x 8 x 16</span>
    <span class="c1"># 8 x 8 x 16    -&gt;  2 x 2 x 8</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">lays</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">lays</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">lays</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    <span class="c1"># decoder</span>
    <span class="c1"># 2 x 2 x 8    -&gt;  8 x 8 x 16</span>
    <span class="c1"># 8 x 8 x 16   -&gt;  16 x 16 x 32</span>
    <span class="c1"># 16 x 16 x 32  -&gt;  32 x 32 x 1</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">lays</span><span class="o">.</span><span class="n">conv2d_transpose</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">lays</span><span class="o">.</span><span class="n">conv2d_transpose</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">lays</span><span class="o">.</span><span class="n">conv2d_transpose</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span>
</pre></div>
</div>
<div class="figure align-center" id="id1">
<a class="reference internal image-reference" href="../../_images/ae.png"><img alt="../../_images/ae.png" src="../../_images/ae.png" style="width: 259.0px; height: 143.0px;" /></a>
<p class="caption"><span class="caption-text"><strong>Figure 1:</strong> Autoencoder</span></p>
</div>
<p>The MNIST dataset contains vectorized images of 28X28. Therefore we
define a new function to reshape each batch of MNIST images to 28X28 and
then resize to 32X32. The reason of resizing to 32X32 is to make it a
power of two and therefore we can easily use the stride of 2 for
downsampling and upsampling.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">transform</span>

<span class="k">def</span> <span class="nf">resize_batch</span><span class="p">(</span><span class="n">imgs</span><span class="p">):</span>
    <span class="c1"># A function to resize a batch of MNIST images to (32, 32)</span>
    <span class="c1"># Args:</span>
    <span class="c1">#   imgs: a numpy array of size [batch_size, 28 X 28].</span>
    <span class="c1"># Returns:</span>
    <span class="c1">#   a numpy array of size [batch_size, 32, 32].</span>
    <span class="n">imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">resized_imgs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">resized_imgs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">imgs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">resized_imgs</span>
</pre></div>
</div>
<p>Now we create an autoencoder, define a square error loss and an
optimizer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="n">ae_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># input to the network (MNIST images)</span>
<span class="n">ae_outputs</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">ae_inputs</span><span class="p">)</span>  <span class="c1"># create the Autoencoder network</span>

<span class="c1"># calculate the loss and optimize the network</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">ae_outputs</span> <span class="o">-</span> <span class="n">ae_inputs</span><span class="p">))</span>  <span class="c1"># claculate the mean square error loss</span>
<span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="c1"># initialize the network</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
</pre></div>
</div>
<p>Now we can read the batches, train the network and finally test the
network by reconstructing a batch of test images.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">input_data</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># Number of samples in each batch</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">5</span>     <span class="c1"># Number of epochs to train the network</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span>        <span class="c1"># Learning rate</span>

<span class="c1"># read MNIST dataset</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s2">&quot;MNIST_data&quot;</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># calculate the number of batches per epoch</span>
<span class="n">batch_per_ep</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_examples</span> <span class="o">//</span> <span class="n">batch_size</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>  <span class="c1"># epochs loop</span>
        <span class="k">for</span> <span class="n">batch_n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_per_ep</span><span class="p">):</span>  <span class="c1"># batches loop</span>
            <span class="n">batch_img</span><span class="p">,</span> <span class="n">batch_label</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># read a batch</span>
            <span class="n">batch_img</span> <span class="o">=</span> <span class="n">batch_img</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>               <span class="c1"># reshape each sample to an (28, 28) image</span>
            <span class="n">batch_img</span> <span class="o">=</span> <span class="n">resize_batch</span><span class="p">(</span><span class="n">batch_img</span><span class="p">)</span>                          <span class="c1"># reshape the images to (32, 32)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">train_op</span><span class="p">,</span> <span class="n">loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">ae_inputs</span><span class="p">:</span> <span class="n">batch_img</span><span class="p">})</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Epoch: {} - cost= {:.5f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">ep</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">c</span><span class="p">))</span>

    <span class="c1"># test the trained network</span>
    <span class="n">batch_img</span><span class="p">,</span> <span class="n">batch_label</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">batch_img</span> <span class="o">=</span> <span class="n">resize_batch</span><span class="p">(</span><span class="n">batch_img</span><span class="p">)</span>
    <span class="n">recon_img</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">ae_outputs</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">ae_inputs</span><span class="p">:</span> <span class="n">batch_img</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># plot the reconstructed images and their ground truths (inputs)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Reconstructed Images&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">recon_img</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Input Images&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">batch_img</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../credentials/LICENSE.html" class="btn btn-neutral float-right" title="LICENSE" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="cnn.html" class="btn btn-neutral float-left" title="Convolutional Neural Networks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Amirsina Torfi
      <span class="lastupdated">
        Last updated on True.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>